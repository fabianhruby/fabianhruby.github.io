<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
    <meta property="og:type" content="article">
    <meta property="og:title" content="Preprocessing with Scikit-learn Pipelines (1/3)">
    <meta property="og:url"
        content="https://fabianhruby.github.io/posts/2024/preprocessing/preprocessing-pipelines-part1.html">
    <meta property="og:image"
        content="https://fabianhruby.github.io/assets/img/posts/2024/preprocessing/preprocessing-with-scikit-learn-pipelines-part1.jpg">
    <meta property="og:description"
        content="This article explores data preprocessing in machine learning, specifically focusing on scikit-learn pipelines. It highlights the importance of clean data for successful model development. The article explores common data issues including missing values and inconsistent scales, and how scikit-learn pipelines can address these issues. It also introduces the concept of transformers and how they can be used within pipelines.">
    <meta property="article:author" content="Fabian Hruby">
    <meta property="article:tag" content="data science">
    <meta property="article:tag" content="scikit-learn">
    <meta property="article:tag" content="sklearn">
    <meta property="article:tag" content="data preprocessing">
    <meta property="article:tag" content="machine learning">
    <title>Preprocessing with Scikit-learn Pipelines | Part 1 - Byte-Sized Insights</title>
    <link rel="icon" type="image/x-icon" href="/assets/favicon.ico" />
    <script src="https://use.fontawesome.com/releases/v6.3.0/js/all.js" crossorigin="anonymous"></script>
    <!-- Google fonts-->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link
        href="https://fonts.googleapis.com/css2?family=Fira+Sans:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap"
        rel="stylesheet">
    <!-- Core theme CSS (includes Bootstrap)-->
    <link href="/css/styles.css" rel="stylesheet" />
    <link href="/css/prism-atom-dark.css" rel="stylesheet" />
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
        MathJax.Hub.Config({messageStyle: 'none',tex2jax: {preview: 'none'}});
      </script>
    <script type="text/javascript" charset="utf-8" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML,
    https://vincenttam.github.io/javascripts/MathJaxLocal.js"></script>

</head>

<body>
    <!-- Navigation-->
    <nav class="navbar navbar-expand-lg navbar-light" id="mainNav">
        <div class="container px-4 px-lg-5">
            <a class="navbar-brand" href="/index.html">Byte-Sized Insights</a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive"
                aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
                Menu
                <i class="fas fa-bars"></i>
            </button>
            <div class="collapse navbar-collapse" id="navbarResponsive">
                <ul class="navbar-nav ms-auto py-4 py-lg-0">
                    <li class="nav-item"><a class="nav-link px-lg-3 py-3 py-lg-4" href="/index.html">Home</a></li>
                    <li class="nav-item"><a class="nav-link px-lg-3 py-3 py-lg-4" href="/about.html">About</a></li>
                    </li>
                </ul>
            </div>
        </div>
    </nav>
    <!-- Page Header-->
    <header class="masthead"
        style="background-image: url('/assets/img/posts/2024/preprocessing/preprocessing-with-scikit-learn-pipelines-part1.jpg')">
        <div class="container position-relative px-4 px-lg-5">
            <div class="row gx-4 gx-lg-5 justify-content-center">
                <div class="col-md-6 col-lg-8 col-xl-8">
                    <div class="post-heading">
                        <h1>Preprocessing with Scikit-learn Pipelines (1/3)</h1>
                        <h2 class="subheading">Motivation and Standard Transformers</h2>
                        <span class="meta">
                            Posted by Fabian Hruby on Mai 15, 2024
                        </span>
                    </div>
                </div>
            </div>
        </div>
    </header>
    <!-- Post Content-->
    <article class="mb-4">
        <div class="container px-4 px-lg-5">
            <div class="row gx-4 gx-lg-6 justify-content-center">
                <div class="col-md-10 col-lg-10 col-xl-8">
                    <h2>Introduction</h2>
                    <p>You have probably come across the phrase "garbage in, garbage out" when reading articles or books
                        on machine learning. This phrase relates to the fact that data with a high quality is the key if
                        you want to successfully develop a model which really adds value. That's where data
                        preprocessing comes in, as it's a fundamental step in the machine learning lifecycle with a
                        significant impact on model performance and efficiency.</p>
                    <p>In this three-part series, we'll take a look at the world of data preprocessing using
                        scikit-learn
                        pipelines.
                        <strong>Part 1</strong> explores the "why" and "how" of preprocessing, focusing on standard
                        transformers and their limitations.
                        <a href="/posts/2024/preprocessing/preprocessing-pipelines-part2.html">Part 2</a> will explore
                        more advanced techniques for handling categorical data and
                        building custom transformers, while <strong>part 3</strong> will introduce scikit-learn's
                        ColumnTransformer, which is suitable for applying transformations to heterogeneous datasets
                        (datasets with different data types).
                    </p>
                    <h2>Why do we even want to preprocess our data?</h2>
                    <p>Clean and properly scaled data is critical to successfully training machine learning models - and
                        here's why:</p>
                    <p>
                    <ul>
                        <li>
                            <h3> Missing or incorrect Values</h3>
                            Data collection isn't always perfect and you may come across missing or incorrect values.
                            These missing and incorrect values can confuse your model and lead to inaccurate
                            predictions. Preprocessing techniques such as imputation (filling in missing values) or
                            deletion ensure that your data is valid and ready for model building.
                        </li>
                        </p>
                        <p>
                            <li>
                                <h3>Different Scales</h3>
                                Imagine that one feature in your data represents income in dollars (from 0 to millions),
                                and another represents age in years (0 to 100).. If you feed this directly into a model,
                                the income feature will overwhelm the age feature due to its larger scale. This can
                                cause the model to prioritise income over age, even though age may be a more important
                                factor for your prediction. Preprocessing techniques such as scaling or normalization
                                address this by putting all features on a similar scale.
                            </li>
                        </p>
                    </ul>
                    By handling missing values and ensuring consistent scales, preprocessing helps your machine learning
                    model focus on the actual relationships within your data. This leads to cleaner, more accurate and
                    more interpretable results.

                    <p>In addition to these, there are other reasons to preprocess data, such as:
                    <ul>
                        <li>
                            <h3>Encoding Categorical Features</h3>
                            Many models can't understand text labels directly. Preprocessing techniques such as one-hot
                            encoding transform categorical features (such as "red", "blue", "green") into numerical
                            representations that the model can work with.
                        </li>
                        </p>
                        <p>
                            <li>
                                <h3>Handling Outliers</h3>
                                Extreme outliers can skew your model's predictions. Preprocessing techniques such as
                                capping address these outliers without discarding valuable data points.
                            </li>
                    </ul>
                    </p>
                    <h2>Enter the Pipeline: A Streamlined Approach with Scikit-learn</h2>
                    <p>

                        Scikit-learn describes a pipeline as follows:<br>
                    <blockquote class="blockquote">
                        A sequence of data transformers with an optional final predictor.
                        <br><br>
                        Pipeline allows you to sequentially apply a list of transformers to
                        preprocess the
                        data
                        and,
                        if desired, conclude the sequence with a final predictor for predictive modeling.
                        <br><br>
                        – <cite><a
                                href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html">Scikit-learn
                                Pipeline</a></cite>
                    </blockquote>
                    In order to understand how a pipeline works and how you can utilize it, we will use a very simple
                    script. I'll explain the different parts step by step to give you a good understanding of what's
                    going on.
                    <br><br>
                    But first, let's have a quick look at the data we will be working with in this preprocessing series:
                    <br><br>
                    <img class="img-fluid"
                        src="/assets/img/posts/2024/preprocessing/preprocessing-with-scikit-learn-pipelines-part1-data.png">
                    <br>
                    </p>
                    <p>
                        In this post, we will focus on the erroneous data in the yellow rectangles. The data points
                        highlighted in red are the ones we will be looking at in part two.
                        <br><br>
                        As you can see, we are only focusing on the numerical columns. The problem with these data
                        points is obvious: we have missing data, but we will find a way to fix this – with a simple
                        preprocessing
                        pipeline from scikit-learn's <incode>Pipeline</incode> class.
                        <br><br>
                        Here is the code that we will discuss step by step to gain insight into a standard
                        preprocessing pipeline:
                    </p>
                    <pre>
<code class="language-python">"""Script for preprocessing data"""

import numpy as np
import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import MinMaxScaler

# Path to our raw data
DATA_PATH = "data/data.xlsx"

# Reading in data and converting the postal_code column as an integer
raw_data = pd.read_excel(DATA_PATH, converters={"postal_code": int})

# Selecting the columns in which missing values should be imputed
cols_to_impute = ["age", "experience_in_years", "salary_in_dollar"]

# Creating our Pipeline object with a SimpleImputer and MinMaxScaler from sklearn
pipeline = Pipeline([
    ("MeanImputer", SimpleImputer(missing_values=np.nan, strategy="mean")),
    ("MinMaxScaler", MinMaxScaler()),
])

# Coping our raw_data and imputing missing values with the column's mean
imputed_data = raw_data.copy()
imputed_data[cols_to_impute] = pipeline.fit_transform(raw_data[cols_to_impute])
</code>
</pre>
                    <br>
                    Here's a step-by-step breakdown of the above (simple) pipeline for imputing missing values
                    and scaling numeric features:
                    <br><br>
                    <h3 class="pad-code">1. Import Necessary Libraries</h3>
                    <pre><code class="language-python">import numpy as np
import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import MinMaxScaler
</code></pre>
                    <br>
                    <h3 class="pad-code">2. Load and Prepare Data</h3>
                    <pre><code class="language-python">DATA_PATH = "data/data.xlsx"
raw_data = pd.read_excel(DATA_PATH, converters={"postal_code": int})
</code></pre>
                    <ul>
                        <li>Replace <incode>data/data.xlsx</incode> with the path to your actual data file.
                        </li>
                        <li>The <incode>converters</incode> parameter in
                            <incode>pd.read_excel</incode> ensures the
                            <incode>postal_code</incode> column is read as integers.
                        </li>
                    </ul>
                    <br>
                    <h3 class="pad-code">3. Select Columns to Impute and Scale</h3>
                    <pre><code class="language-python">cols_to_impute = ["age", "experience_in_years", "salary_in_dollar"]
</code></pre>
                    <br>
                    <h3 class="pad-code">4. Simple Imputation for Missing Values</h3>
                    <pre><code class="language-python">pipeline = Pipeline([
("MeanImputer", SimpleImputer(missing_values=np.nan, strategy="mean")),
("MinMaxScaler", MinMaxScaler()),
])
</code></pre>
                    <p>Here it is: the construction of our <incode>Pipeline</incode> object named
                        <incode>pipeline</incode>:
                    </p>
                    <img class="img-fluid"
                        src="/assets/img/posts/2024/preprocessing/preprocessing-with-scikit-learn-pipelines-part1-pipeline.png"
                        width="50%">
                    <p><strong>Important Note</strong>: While selecting columns within the pipeline might seem
                        convenient for this
                        example,
                        it is generally not recommended. This approach becomes inflexible when you have datasets with
                        varying column types. In the third part of this series we'll explore scikit-learn's
                        <incode>ColumnTransformer</incode>, a more
                        versatile approach for handling heterogeneous datasets.
                    </p>
                    <p>As you can see, the <incode>pipeline</incode> object is created by passing a list to
                        scikit-learn's <incode>Pipeline</incode>. The first element in the tuple is the name of the
                        step, which you can choose freely. The second element is the transformation you want to apply to
                        your data. Note that all these steps must be "transforms", which means, that they must implement
                        a <incode>fit</incode> and a <incode>transform
                        </incode> method. We will have a
                        look at this when we will talk about custom transformers in the second part of this series.
                    </p>
                    <p>In our case, we are using two transformations:
                    <ul>
                        <li>
                            <h4>
                                SimpleImputer
                            </h4>
                            The simple imputer does what its name says: it imputes (missing) values based on a (simple)
                            chosen strategy (<incode>"mean"</incode>, <incode>"median"</incode>,
                            <incode>"most_frequent"</incode>, <incode>"constant"</incode>). In our case, the strategy is
                            <incode>"mean"</incode>. This means that any missing values in the transformed column will
                            be
                            replaced by the mean of the corresponding column in which the missing value appears. I will
                            not go into any further details and other imputers here as this would go beyond the scope of
                            this article, but you can dig deeper in the <a
                                href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.impute">scikit-learn
                                documentation on imputing</a>.<br>
                            <br>
                            The <incode>missing_values</incode> parameter,allows you to specify the format of the
                            missing values, if you want to. Although <incode>mean</incode> and <incode>np.nan</incode>
                            are
                            the default values for <incode>strategy</incode> and <incode>missing_values</incode>,
                            I wanted to include them to show you that you can tweak the <incode>
                                SimpleImputer</incode> to suit your needs.

                        </li>
                        <br>
                        <li>
                            <h4>MinMaxScaler</h4>
                            Min-max scaling is a widely used scaling technique for scaling values in a
                            fixed range between 0 and 1. The mathematical formula is as follows:

                            $$x_{scaled} = \frac{x - X_{min}}{X_{max} - X_{min}}$$

                            <span style="font-style:italic">x_scaled</span>: The scaled value ranging between 0 and
                            1<br>
                            <span style="font-style:italic">x</span>: The value which will be scaled<br>
                            <span style="font-style:italic">X_min</span>: The minimum value of all X values in the
                            column<br>
                            <span style="font-style:italic">X_max</span>: The maximum value of all X values in the
                            column<br>
                            <br>
                            <incode>MinMaxScaler</incode> is only one of <a
                                href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing">
                                many scaling techniques available in
                                scikit-learn</a>. The choice of scaler depends on your specific data and the
                            desired
                            outcome.
                        </li>
                    </ul>
                    </p>
                    <h3 class="pad-code">5. Impute and Scale (on a copy)</h3>
                    <pre><code class="language-python">imputed_data = raw_data.copy()
imputed_data[cols_to_impute] = pipeline.fit_transform(raw_data[cols_to_impute])
</code></pre>
                    <p>
                        We create a copy of the raw data named <incode>imputed_data</incode> to avoid modifying the
                        original
                        data. Then, we
                        use the pipeline to transform the columns containing missing values
                        <incode>cols_to_impute</incode>.
                    </p>
                    <p>There you have it: your missing values are imputed<br><br>
                        <img class="img-fluid"
                            src="/assets/img/posts/2024/preprocessing/preprocessing-with-scikit-learn-pipelines-part1-data-imputed.png">
                        <span class="annotation">This screenshot has been added for
                            demonstration purposes.
                            Normally, you wouldn't see this intermediate step.</span><br><br>
                        ... and then scaled
                        <br><br>
                        <img class="img-fluid"
                            src="/assets/img/posts/2024/preprocessing/preprocessing-with-scikit-learn-pipelines-part1-data-scaled.png">
                    </p>
                    <p>
                        As you can see, your transformations worked!
                        <li>We have no missing values</li>
                        <li>Our columns are scaled so that the smallest unscaled value is 0 and the largest unscaled
                            value is now 1. All other values are between 0 and 1.</li>
                    </p>
                    <p>
                    <h4>Details about fit, transform and fit_transform</h4>
                    Even if I have said that I won't go into any details regarding <incode>fit</incode> and <incode>
                        transform</incode> in this post, I would still like to add a brief note.<br>
                    To finally apply our pipeline to our data, we used the <incode>fit_transform</incode> method.
                    Therefore, I would like to explain very briefly what the <incode>fit_transform</incode> method
                    is all about. <incode>fit_transform</incode> is a method that combines the two methods <incode>
                        fit</incode> and <incode>transform</incode> and is simply for convenience. Internally, the
                    <incode>fit</incode> method is executed first, which learns the properties of the data that are
                    then used in the <incode>transform</incode> method. In our case, this was the "learning" of the
                    minimum and maximum values of our columns, as these are needed for our <incode>MinMaxScaler
                    </incode> (see formula
                    above). In other transformations (such as e.g. <incode>StandardScaler</incode> does), other
                    properties
                    such as the mean and standard deviation are
                    learned.
                    <br><br>
                    <h2>Conclusion</h2>
                    <p>
                        Preprocessing pipelines in scikit-learn provide a structured and efficient way to prepare your
                        data for machine learning. By chaining preprocessing steps together, you can ensure consistency
                        and clarity in your data transformations. This first part lays the foundation for understanding
                        pipelines. In the <a href="/posts/2024/preprocessing/preprocessing-pipelines-part2.html">next
                            part of this series</a>, we'll take a look at more advanced techniques and
                        explore how to use function transformers and build custom transformers to solve more complex
                        data preprocessing challenges. In the third part, we'll also explore scikit-learn's <incode>
                            ColumnTransformer</incode>, a more versatile approach to handling heterogeneous datasets.
                    </p>
                </div>

            </div>
        </div>
    </article>
    <!-- Footer-->
    <footer class="border-top">
        <div class="container px-4 px-lg-5">
            <div class="row gx-4 gx-lg-5 justify-content-center">
                <div class="col-md-10 col-lg-8 col-xl-7">
                    <ul class="list-inline text-center">
                        <li class="list-inline-item">
                            <a class="logo" href="https://www.linkedin.com/in/fabian-hruby-36b932100/">
                                <span class="fa-stack fa-lg">
                                    <i class="fas fa-circle fa-stack-2x"></i>
                                    <i class="fab fa-linkedin fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li>
                        <li class="list-inline-item">
                            <a class="logo" href="https://github.com/fabianhruby">
                                <span class="fa-stack fa-lg">
                                    <i class="fas fa-circle fa-stack-2x"></i>
                                    <i class="fab fa-github fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li>
                    </ul>
                    <div class="small text-center text-muted fst-italic">Copyright &copy; Byte-Sized Insights 2024
                    </div>
                </div>
            </div>
        </div>
    </footer>
    <!-- Bootstrap core JS-->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js"></script>
    <!-- Core theme JS-->
    <script src="/js/scripts.js"></script>
    <script src="/js/prism.js"></script>
</body>

</html>
